README for `experiment` python code

## Python Scripts
The python scripts fit a single RNN to a data using SGD with TBPTT:
* `synth_script.py` the python script for the synthetic experiments.
* `language_script.py` the python script for the language model experiments.
* `temporal_pp_model` the python script for the temporal point process experiments.

See each `<name>_script.py --help` for details on the arguments (e.g. `--experiment_folder`, `--K`, `--lr`, `--init_num` etc.).
Each `<name>_script.py` checkpoint metrics and figures to `--experiment_folder` location (default is `<repo>/output/<experiment_name>`).

For the experiments in the paper, we call these scripts multiple times with different arguments.
The specific arguments used detailed in `<repo>/scripts/<experiment_name>.sh` (and in `script_maker.py`).

## Helper Files
Helper python files provide utility functions:
* `synth_model.py`, `language_model.py`, and `temporal_pp_model.py` are helper files that provide the custom PyTorch `nn.module` for the python scripts.
* `script_maker.py` a helper python script to create bash scripts that call `<name>_script.py`. To run jobs in parallel, modify the `num_splits` parameter to split jobs into multiple bash scripts. To enable/disable use of CUDA modify the `CUDA_AVALIABLE` parameter.
* `aggregate_output.py` a helper python script that aggregates the output of the bash scripts.

The bash scripts in `scripts/` folder are generated by calling `python experiments/script_maker.py`.
The bash scripts call the python scripts in serial for each set of experiments args (e.g. `--K`, `--lr`, etc.) for a list of experiment arguments.
After running a set of experiments, we aggregate the output of individual runs using `python experiments/aggregate_output.py --path_to_data <experiment_folder>`.

